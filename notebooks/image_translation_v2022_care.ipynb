{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup libraries\n",
    "Let's start with some imports. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "\n",
    "# autoreload modules before executing\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import sys\n",
    "# Setup pretty printing\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import download_and_extract_zip_file, plot_some\n",
    "from csbdeep.data import RawData, create_patches\n",
    "\n",
    "# importing some utilities from microDL in the first half.\n",
    "# Add microdl path to sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(\"System path: \"+module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import micro_dl.utils.image_utils as im_utils\n",
    "import micro_dl.utils.masks as mask_utils\n",
    "import micro_dl.utils.normalize as norm_utils\n",
    "TOP_DIR = os.path.expanduser('~/CompMicro/projects/virtualstaining/MBL_DL_image_translation')\n",
    "INPUT_DIR = os.path.join(TOP_DIR, 'data/')\n",
    "MODEL_DIR = os.path.join(TOP_DIR, 'care_model')\n",
    "patch_file = INPUT_DIR+'phase_dna_care.npz'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Prepare dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positions = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "# Copy the data in a format expected by CARE pipeline. \n",
    "# CARE data generator requires the source and target files to be saved in different formats with matching filenames.\n",
    "\n",
    "# subset retardance images\n",
    "if not os.path.exists(INPUT_DIR + 'care_retardance'):\n",
    "    os.mkdir(INPUT_DIR + 'care_retardance')\n",
    "for pos in positions:\n",
    "    srcfiles= glob.glob(INPUT_DIR + 'img_Retardance_*p{:03d}'.format(pos)+ '*')\n",
    "    dstfiles= [path.replace('img_Retardance_','care_retardance/img_') for path in srcfiles]\n",
    "    for src, dst in zip(srcfiles,dstfiles):\n",
    "        shutil.copy(src,dst)\n",
    "\n",
    "# subset phase images\n",
    "if not os.path.exists(INPUT_DIR + 'care_phase'):\n",
    "    os.mkdir(INPUT_DIR + 'care_phase')\n",
    "for pos in positions:\n",
    "    srcfiles= glob.glob(INPUT_DIR + 'img_phase_*p{:03d}'.format(pos)+ '*')\n",
    "    dstfiles= [path.replace('img_phase_','care_phase/img_') for path in srcfiles]\n",
    "    for src, dst in zip(srcfiles,dstfiles):\n",
    "        shutil.copy(src,dst)\n",
    "        \n",
    "# subset F-actin images\n",
    "if not os.path.exists(INPUT_DIR + 'care_factin'):\n",
    "    os.mkdir(INPUT_DIR + 'care_factin')\n",
    "        \n",
    "for pos in positions:\n",
    "    srcfiles= glob.glob(INPUT_DIR + 'img_568_*p{:03d}'.format(pos)+ '*')\n",
    "    dstfiles= [path.replace('img_568_','care_factin/img_') for path in srcfiles]\n",
    "    for src, dst in zip(srcfiles,dstfiles):\n",
    "        shutil.copy(src,dst)\n",
    "\n",
    "# subset DNA images\n",
    "if not os.path.exists(INPUT_DIR + 'care_dna'):\n",
    "    os.mkdir(INPUT_DIR + 'care_dna')\n",
    "        \n",
    "for pos in positions:\n",
    "    srcfiles= glob.glob(INPUT_DIR + 'img_405_*p{:03d}'.format(pos)+ '*')\n",
    "    dstfiles= [path.replace('img_405_','care_dna/img_') for path in srcfiles]\n",
    "    for src, dst in zip(srcfiles,dstfiles):\n",
    "        shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore input and target images <a class=\"anchor\" id=\"explore\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to translate 2D slices of phase or retardance image into 2D slices of fluorescene images of F-actin and DNA. Let's start by looking at some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libaries again if the plots don't display properly\n",
    "img_name = 'img_t000_p003_z010.tif'\n",
    "actin_path = os.path.join(INPUT_DIR, 'care_factin/', img_name) #F-actin was imaged with Alexa Fluor 568 using 468nm excitation wavelength.\n",
    "dna_path=os.path.join(INPUT_DIR, 'care_dna/', img_name) # DNA was imaged with Hoechst using 405nm excitation wavelength.\n",
    "input_path=os.path.join(INPUT_DIR,'care_retardance/', img_name) # the phase and polarization were imaged using 530nm wavelength.\n",
    "\n",
    "actin = imread(actin_path)\n",
    "# This will clip the top and bottom 1% of intensitites\n",
    "actin = norm_utils.hist_clipping(actin, 1, 99)\n",
    "dna = imread(dna_path)\n",
    "dna = norm_utils.hist_clipping(dna, 1, 99)\n",
    "im_input = imread(input_path) \n",
    "im_input = norm_utils.hist_clipping(im_input, 0.8, 99.5) \n",
    "fig, ax = plt.subplots(1, 3)\n",
    "fig.set_size_inches(20, 15)\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(im_input, cmap='gray')\n",
    "ax[0].set_title('Input phase',fontsize=20)\n",
    "ax[1].imshow(actin, cmap='gray')\n",
    "ax[1].set_title('Target F-actin',fontsize=20)\n",
    "ax[2].imshow(dna, cmap='gray')\n",
    "ax[2].set_title('Target DNA',fontsize=20)\n",
    "for a in ax: a.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data generator and patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csbdeep.data import no_background_patches, norm_percentiles, sample_percentiles\n",
    "\n",
    "raw_data = RawData.from_folder (\n",
    "    basepath    = INPUT_DIR,\n",
    "    source_dirs = ['care_phase'],\n",
    "    target_dir  = 'care_dna',\n",
    "    axes        = 'YX',\n",
    ")\n",
    "\n",
    "X, Y, XY_axes = create_patches (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (256,256),\n",
    "    patch_filter        = no_background_patches(0.5),\n",
    "    n_patches_per_image = 128,\n",
    "    save_file           = patch_file,\n",
    ")\n",
    "# TODO: include augmentations (transforms = ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)])\n",
    "    plt.show()\n",
    "None;\n",
    "## TODO: plot in grayscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. 2D virtual staining (slice$\\rightarrow$slice) using CARE <a class=\"anchor\" id=\"pilot\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data and configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils import axes_dict, plot_some, plot_history\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "from csbdeep.io import load_training_data\n",
    "from csbdeep.models import Config, CARE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y), (X_val,Y_val), axes = load_training_data(patch_file, validation_split=0.1, verbose=False)\n",
    "\n",
    "c = axes_dict(axes)['C']\n",
    "n_channel_in, n_channel_out = X.shape[c], Y.shape[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(axes, n_channel_in, n_channel_out, unet_kern_size=3, train_batch_size=16, train_steps_per_epoch=10, unet_n_depth = 3, train_epochs = 30, unet_residual = False)\n",
    "print(config)\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config, 'phase2DNA_bath16_depth3', basedir=MODEL_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.summary()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time to train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try restarting the notebook kernel if the gpu memory is occupied and you run into errors about \"can't creat training session\".\n",
    "Training 6 epochs should take no more than 5 minutes if you're on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've completed our first training. Let's take a look at what happened during training by opening a history log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "_P = model.keras_model.predict(X_val[:5])\n",
    "if config.probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(X_val[:5],Y_val[:5],_P,pmax=99.5)\n",
    "plt.suptitle('5 example validation patches\\n'      \n",
    "             'top row: input (source),  '          \n",
    "             'middle row: target (ground truth),  '\n",
    "             'bottom row: predicted from source');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_min = np.min(X_val[:])\n",
    "x_val_max = np.max(X_val[:])\n",
    "print(f'size of validation input: {X_val[:5].shape}, range of validation input: [{x_val_min}, {x_val_max}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Prediction on test position not seen by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test image and scale the uint16 image to match the dynamic range of validation set.\n",
    "\n",
    "im_path = os.path.join(INPUT_DIR, 'img_phase_t000_p011_z013.tif')\n",
    "test_input = imread(im_path).astype('float32')\n",
    "# test_input -= np.mean(test_input[:])\n",
    "# test_input /= np.max(test_input[:])\n",
    "# test_input *= x_val_max\n",
    "# prediction = model.keras_model.predict(test_input.reshape(1,2048,2048,1)) # Note that the input needs to be reshaped in (batch, Y, X, C) order.\n",
    "# prediction = prediction.reshape(2048,2048)\n",
    "\n",
    "prediction = model.predict(test_input, axes = 'YX')\n",
    "\n",
    "im_path = os.path.join(INPUT_DIR, 'img_405_t000_p011_z013.tif')\n",
    "target = imread(im_path)\n",
    "\n",
    "print(f'input range: {np.min(test_input[:])}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "fig.set_size_inches(20, 15)\n",
    "ax = ax.flatten()\n",
    "for a in ax: a.axis('off')\n",
    "    \n",
    "ax[0].imshow(norm_utils.hist_clipping(test_input, 1, 99), \n",
    "             cmap='gray');\n",
    "ax[0].set_title('Input', fontsize=20)\n",
    "\n",
    "ax[1].imshow(norm_utils.hist_clipping(target, 1, 99), \n",
    "             cmap='gray'); \n",
    "ax[1].set_title('Target', fontsize=20)\n",
    "\n",
    "ax[2].imshow(norm_utils.hist_clipping(prediction, 1, 99), \n",
    "             cmap='gray'); \n",
    "ax[2].set_title('Prediction', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint C"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
